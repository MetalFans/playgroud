{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 載入資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /Users/fan/anaconda/bin/Workspace/sentiment/0616/big/jieba356726.txt ...\n",
      "DEBUG:jieba:Building prefix dict from /Users/fan/anaconda/bin/Workspace/sentiment/0616/big/jieba356726.txt ...\n",
      "Dumping model to file cache /var/folders/ws/qq63c39d43l_20sybqcwcf900000gn/T/jieba.u60b07a305259704c4cd827282b04b44e.cache\n",
      "DEBUG:jieba:Dumping model to file cache /var/folders/ws/qq63c39d43l_20sybqcwcf900000gn/T/jieba.u60b07a305259704c4cd827282b04b44e.cache\n",
      "Loading model cost 1.865 seconds.\n",
      "DEBUG:jieba:Loading model cost 1.865 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "DEBUG:jieba:Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import codecs\n",
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "import re\n",
    "import operator\n",
    "import json\n",
    "jieba.set_dictionary('./Workspace/sentiment/0616/big/jieba356726.txt')\n",
    "jieba.load_userdict('./Workspace/sentiment/0616/big/jieba356726.txt')\n",
    "jieba.load_userdict('./Workspace/sentiment/0616/big/cute.txt')\n",
    "jieba.load_userdict('./Workspace/sentiment/0616/food/fooddict2027.txt')\n",
    "jieba.load_userdict('./Workspace/sentiment/0616/menu/menu50806_new.txt')\n",
    "jieba.load_userdict('./Workspace/sentiment/0616/sentiment/negativewords.txt')\n",
    "jieba.load_userdict('./Workspace/sentiment/0616/sentiment/positivewords.txt')\n",
    "jieba.load_userdict('./Workspace/sentiment/0616/sentiment/negative.txt')\n",
    "jieba.load_userdict('./Workspace/sentiment/0616/sentiment/more.txt')\n",
    "jieba.load_userdict('./Workspace/sentiment/0616/sentiment/question.txt')\n",
    "jieba.load_userdict('./Workspace/sentiment/0616/stop/stopword2292.txt')\n",
    "# 負面\n",
    "negdict = []\n",
    "# 正面\n",
    "posdict = []\n",
    "# 否定\n",
    "nodict = []\n",
    "# 程度\n",
    "plusdict = []\n",
    "# 不肯定\n",
    "question = []\n",
    "with codecs.open('./expand/negativeWordMerge.txt', 'r', 'utf-8') as f:\n",
    "    for w in f.readlines():\n",
    "        negdict.append(w.split()[0])\n",
    "with codecs.open('./expand/positiveWordMerge.txt', 'r', 'utf-8') as f:\n",
    "    for w in f.readlines():\n",
    "        posdict.append(w.split()[0])\n",
    "with codecs.open('./expand/inverseWordMerge.txt', 'r', 'utf-8') as f:\n",
    "    for w in f.readlines():\n",
    "        nodict.append(w.split()[0])\n",
    "with codecs.open('./expand/degreeWordMerge.txt', 'r', 'utf-8') as f:\n",
    "    for w in f.readlines():\n",
    "        plusdict.append(w.split()[0])\n",
    "with codecs.open('./Workspace/sentiment/0616/sentiment/question.txt', 'r', 'utf-8') as f:\n",
    "    for w in f.readlines():\n",
    "        question.append(w.split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52226\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "food = set()\n",
    "with codecs.open('./Workspace/sentiment/0616/menu/menu50806_new.txt', 'r','utf-8') as f:\n",
    "    for w in f.readlines():\n",
    "        food.add(w.replace(' 5000 n\\n',''))\n",
    "with codecs.open('./Workspace/sentiment/0616/food/fooddict2027.txt', 'r','utf-8') as f:\n",
    "    for w in f.readlines():\n",
    "        food.add(w.replace(' 5000 n\\n',''))\n",
    "print len(list(food))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "foodlist = []\n",
    "for ele in food:\n",
    "    jb = list(jieba.cut_for_search(ele))\n",
    "    foodlist.extend(jb)\n",
    "foodlist = [ele for ele in list(set(foodlist)) if ele not in food]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8199\n"
     ]
    }
   ],
   "source": [
    "food_from_kmean = ['7','8','15','24','32','34','36','37','42','43','53','54','65','84','86','87','97','99','103','106','110','117','118','122','123','127','140','142','145']\n",
    "with open('./Workspace/data/subjectClustering_minCount_1_n_150.json', 'r') as f:\n",
    "    kmean_result = json.load(f)\n",
    "food_list = []\n",
    "for ele in kmean_result:\n",
    "    if ele in food_from_kmean:\n",
    "        food_list.extend(kmean_result[ele])\n",
    "print len(food_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3053\n"
     ]
    }
   ],
   "source": [
    "food_extend = [ele for ele in food_list if ele not in food]\n",
    "print len(food_extend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./Workspace/data/extend_word.txt', 'w') as f:\n",
    "    for ele in food_extend:\n",
    "        f.write(ele.encode('utf-8') + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立情緒分析類別"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SentimentAnalysis():\n",
    "    \n",
    "    '''建立instance時即讀取字典'''\n",
    "    def __init__(self, negdict, posdict, nodict, plusdict, question, bid, aid, food):\n",
    "        self.score = 0\n",
    "        self._id = bid\n",
    "        self.author_id = aid\n",
    "        self.positiveSubject = []\n",
    "        self.negativeSubject = []\n",
    "        self.negdict = negdict\n",
    "        self.posdict = posdict\n",
    "        self.nodict = nodict\n",
    "        self.plusdict = plusdict\n",
    "        self.question = question\n",
    "        self.food = food\n",
    "        self.adjindex = 0\n",
    "        self.pList = []\n",
    "        self.nList = []\n",
    "    \n",
    "    ''' \n",
    "        [情緒分數]\n",
    "        \n",
    "        計算情緒分數時，先考慮情緒詞正負，再考慮程度與極性      \n",
    "        例如：好吃的義大利麵 => +1\n",
    "             不好吃的義大利麵 => -1\n",
    "             很好吃的義大利麵 => +2\n",
    "             很不好吃的義大利麵 => -2\n",
    "             \n",
    "        考量大部分人傾向用詞委婉，情緒詞正負方向採用不同的處理方式\n",
    "        對於負評的認定較為寬鬆，而對於正評的認定較為嚴格      \n",
    "        例如：這個漢堡不算難吃 => 0\n",
    "             這個漢堡不算好吃 => -1\n",
    "             \n",
    "        當否定詞與情緒詞中間夾雜程度用語時，皆判定為中性偏負           \n",
    "        例如：這個漢堡不算非常難吃 => -0.5\n",
    "             這個漢堡不算非常好吃 => -0.5\n",
    "    '''\n",
    "    def checkDegree(self, sdrange, positive=True):\n",
    "        # 定義初始極性\n",
    "        disturbingWords = [\n",
    "            u'照到',\n",
    "            u'照過',\n",
    "            u'見過',\n",
    "            u'見到',\n",
    "            u'看過',\n",
    "            u'看到',\n",
    "            u'聽過',\n",
    "            u'聽到',\n",
    "            u'吃過',\n",
    "            u'吃到',\n",
    "            u'用過',\n",
    "            u'用到',\n",
    "            u'喝過',\n",
    "            u'喝到',\n",
    "            u'聞過',\n",
    "            u'聞到',\n",
    "            u'碰過',\n",
    "            u'碰到',\n",
    "            u'遇過',\n",
    "            u'遇到',\n",
    "            u'去過',\n",
    "            u'貼過',\n",
    "            u'拍過',\n",
    "            u'拍到',\n",
    "            u'推過',\n",
    "            u'試過'\n",
    "        ]\n",
    "        if positive:\n",
    "            pollar = 1\n",
    "        else:\n",
    "            pollar = -1\n",
    "        # 定義初始程度\n",
    "        degree = 1\n",
    "        # 在指定範圍內撈否定詞、程度詞\n",
    "        for i in xrange(len(sdrange)):\n",
    "            st = sdrange[i]\n",
    "            # 標記程度用語是否出現在否定詞之前\n",
    "            flag = False\n",
    "            # 標記程度用語是否穿插在否定詞與情緒詞之間\n",
    "            ambiguous = False\n",
    "            # 標記是否為負面情緒詞前面含負面詞而不含程度詞\n",
    "            excp = False\n",
    "            # 遇到否定用語就改變極性方向\n",
    "            if st in self.nodict:\n",
    "                if i == len(sdrange)-1:\n",
    "                    self.adjindex = len(sdrange)-i\n",
    "                    pollar *= -1\n",
    "                elif sdrange[i+1] not in disturbingWords:\n",
    "                    self.adjindex = len(sdrange)-i\n",
    "                    pollar *= -1\n",
    "            # 若含程度用語\n",
    "            if st in self.plusdict:\n",
    "                flag = True\n",
    "                # 在程度用語前面的範圍找否定詞\n",
    "                for j in xrange(i):\n",
    "                    if sdrange[j] in self.nodict and sdrange[j+1] not in disturbingWords:\n",
    "                        flag = False\n",
    "                        # 找到代表程度用語穿插在否定詞語情緒詞之間，予以標記\n",
    "                        ambiguous = True\n",
    "                        break\n",
    "                # 若程度用語出現在否定詞之前則乘數設為2\n",
    "                if flag:\n",
    "                    degree = 2\n",
    "                # 若程度用語穿插在否定詞語情緒詞之間，正向詞乘數為-0.5，負向詞乘數為0.5，最後各自乘上極性後分數同為-0.5\n",
    "                elif ambiguous:\n",
    "                    if pollar == 1 :\n",
    "                        degree = -0.5\n",
    "                    else:\n",
    "                        degree = 0.5\n",
    "            # 負向詞遇到否定詞，若沒有程度詞修飾，直接認定為中性\n",
    "            elif not positive:\n",
    "                for x in xrange(len(sdrange)):\n",
    "                    if sdrange[x] in self.nodict:\n",
    "                        excp = True\n",
    "                        break\n",
    "        if excp:\n",
    "            return 0\n",
    "        else:\n",
    "            return pollar * degree\n",
    "        \n",
    "    '''\n",
    "        [情緒分數加總]\n",
    "        \n",
    "        找到情緒詞後往前找3個詞，把3個詞丟進checkDegree判斷規則，回傳該情緒詞的分數\n",
    "        每次計算完分數，判斷正負號，再執行getSubject去抓取正負主題詞，結果存入self.positiveSubject/self.negativeSubject\n",
    "        並把每次的計算分數累加存入self.score\n",
    "        \n",
    "    '''\n",
    "    def sentimentScore(self, sd):\n",
    "        words = sd\n",
    "        self.pList = []\n",
    "        self.nList = []\n",
    "        # 含這些髒東西的句子之後會被跳過\n",
    "        #pattern = u'文章|本文'\n",
    "        # 搜尋情緒詞時用倒著找的方式，便於之後主題詞的抓取\n",
    "        for i in xrange(len(words)):\n",
    "            self.adjindex = 0\n",
    "            p = 0\n",
    "            possbj = None\n",
    "            negsbj = None\n",
    "            #遇到髒東西或者是出現使整個句子情緒方向不定的字眼時直接跳過 ex: 見仁見智\n",
    "            #if re.search(pattern, ''.join(words)) or words[i] in self.question:\n",
    "            #    break\n",
    "            # 定義選取範圍\n",
    "            if i > 2:\n",
    "                n = 3\n",
    "            else:\n",
    "                n = i\n",
    "            # 若出現在負面詞\n",
    "            if words[i] in self.negdict:\n",
    "                if n > 0:\n",
    "                    p = self.checkDegree(words[i-n:i],positive=False)\n",
    "                    self.score += p\n",
    "                else:\n",
    "                    p = -1\n",
    "                    self.score += p\n",
    "            # 若出現在正面詞\n",
    "            elif words[i] in self.posdict:\n",
    "                if n > 0:\n",
    "                    p = self.checkDegree(words[i-n:i],positive=True)\n",
    "                    self.score += p\n",
    "                else:\n",
    "                    p = 1\n",
    "                    self.score += p\n",
    "            # 分別抓取正負情緒詞所對應的主題詞，存入positiveSubject/negativeSubject\n",
    "            # 主題詞只保留2個字以上的\n",
    "            if p > 0:\n",
    "                possbj = self.getSubject(i-self.adjindex, sd)\n",
    "                if possbj and len(possbj)>1:\n",
    "                    self.pList.append((possbj, words[i]))\n",
    "            elif p < 0:\n",
    "                negsbj = self.getSubject(i-self.adjindex, sd)\n",
    "                if negsbj and len(negsbj)>1:\n",
    "                    self.nList.append((negsbj,words[i]))\n",
    "        self.positiveSubject.extend(self.pList)\n",
    "        self.negativeSubject.extend(self.nList)\n",
    "                    \n",
    "    '''\n",
    "        [主題詞抓取原則]\n",
    "        \n",
    "        找到情緒詞後，先往後找名詞，並確認是否已在清單中\n",
    "        若找不到或者是找到的詞已在清單中，則再往前找名詞\n",
    "    '''   \n",
    "    def getSubject(self, index, sd):\n",
    "        subject = None\n",
    "        end = len(sd)-1\n",
    "        rindex = index\n",
    "        lindex = index\n",
    "        # 是否繼續往前找\n",
    "        keepgoing = True\n",
    "        # 把目前已有的positiveSubject/negativeSubject合併\n",
    "        temp = map(operator.itemgetter(0), self.pList) + map(operator.itemgetter(0), self.nList)\n",
    "        # 往左找\n",
    "        lcount = 0\n",
    "        while(lindex > 0):\n",
    "            lcount += 1\n",
    "            if lcount > 3:\n",
    "                break\n",
    "            lindex -= 1\n",
    "            word = sd[lindex]\n",
    "            if word in food:\n",
    "                if word not in temp:\n",
    "                    subject = word\n",
    "                    keepgoing = False\n",
    "                break\n",
    "#                 else:\n",
    "#                     try:\n",
    "#                         similarWords = model.most_similar(word, topn=10)\n",
    "#                         bingo = False\n",
    "#                         for w in similarWords:             \n",
    "#                             if w in food:\n",
    "#                                 bingo = True\n",
    "#                                 break\n",
    "#                         if word not in temp and bingo:\n",
    "#                             subject = word\n",
    "#                             keepgoing = False\n",
    "#                             break\n",
    "#                     except KeyError:\n",
    "#                         pass\n",
    "        # 若往左找沒找到或者找到的已在清單中，則往後找\n",
    "        rcount = 0\n",
    "        if keepgoing:\n",
    "            while(rindex < end):\n",
    "                rcount += 1\n",
    "                if rcount > 3:\n",
    "                    break\n",
    "                rindex += 1\n",
    "                word = sd[rindex]\n",
    "                if word in food:\n",
    "                    if word not in temp:\n",
    "                        subject = word\n",
    "                        keepgoing = False\n",
    "                    break\n",
    "    #             else:\n",
    "    #                 try:\n",
    "    #                     similarWords = model.most_similar(word, topn=10)\n",
    "    #                     bingo = False\n",
    "    #                     for w in similarWords:             \n",
    "    #                         if w in food:\n",
    "    #                             bingo = True\n",
    "    #                             break\n",
    "    #                     if word not in temp and bingo:\n",
    "    #                         subject = word\n",
    "    #                         keepgoing = False\n",
    "    #                         break\n",
    "    #                 except KeyError:\n",
    "    #                     pass\n",
    "        return subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 測試文章"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./Workspace/simpleBlog.json', 'r') as f:\n",
    "    text = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./Workspace/data/blog_perfect_cut.json', 'r') as f:\n",
    "    ifoodie = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1044.49092603\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "output = []\n",
    "for ele in ifoodie:\n",
    "    result = {}\n",
    "    s_analysis = SentimentAnalysis(negdict, posdict, nodict, plusdict, question, ele, ifoodie[ele]['author_id'], food)\n",
    "    for sentence in ifoodie[ele]['article']:\n",
    "        s_analysis.sentimentScore(sentence)\n",
    "    result['_id'] = s_analysis._id\n",
    "    result['author_id'] = s_analysis.author_id\n",
    "    result['positiveSubject'] = s_analysis.positiveSubject\n",
    "    result['negativeSubject'] = s_analysis.negativeSubject\n",
    "    result['score'] = s_analysis.score\n",
    "    output.append(result)\n",
    "print time.time()-start\n",
    "# with open('./Workspace/data/sentimentResult_20160701.json', 'w') as f:\n",
    "#     json.dump(output, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./Workspace/ifoodieBlogDic20160619Update5PixnetSmallEnglish.json', 'r') as f:\n",
    "    blog = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for ele in output:\n",
    "    blog[ele['_id']]['positiveSubject'] = ele['positiveSubject']\n",
    "    blog[ele['_id']]['negativeSubject'] = ele['negativeSubject']\n",
    "    blog[ele['_id']]['score'] = ele['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./Workspace/result/BlogWithSubject.json', 'w') as f:\n",
    "    json.dump(blog, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.102883815765\n",
      "情緒總分：10.5\n",
      "positive 摃丸 有名\n",
      "positive 日式拉麵 愛好者\n",
      "positive 豚骨拉麵 最愛\n",
      "positive 糖心蛋 愛吃\n",
      "positive 豚骨拉麵 濃厚\n",
      "positive 拉麵 品嘗\n",
      "positive 豚骨拉麵 濃厚\n",
      "positive 糖心蛋 咬勁\n",
      "positive 蛋白 滑嫩\n",
      "positive 拉麵 濃厚\n",
      "positive 拉麵 濃厚\n",
      "negative 拉麵 親切\n",
      "negative 叉燒 滿意\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "result = {}\n",
    "ri = random.randint(0,len(ifoodie))\n",
    "art = ifoodie.values()[ri]['article']\n",
    "start = time.time()\n",
    "s_analysis = SentimentAnalysis(negdict, posdict, nodict, plusdict, question, 'b1', 'a1',food)\n",
    "for sentence in art:\n",
    "    s_analysis.sentimentScore(sentence)\n",
    "    result['_id'] = s_analysis._id\n",
    "result['positiveSubject'] = s_analysis.positiveSubject\n",
    "result['negativeSubject'] = s_analysis.negativeSubject\n",
    "result['score'] = s_analysis.score\n",
    "print time.time()-start\n",
    "print '情緒總分：%s' % str(s_analysis.score)\n",
    "for ele in s_analysis.positiveSubject:\n",
    "    print 'positive', ele[0], ele[1]\n",
    "for ele in s_analysis.negativeSubject:\n",
    "    print 'negative', ele[0], ele[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571782cb51ba803f7fb0101f\n",
      "新竹市 東區 日式豚骨拉麵 心得 食記 博多 一幸 舍 這天 家人 來到 新竹 玩\n",
      "說 新竹 最 有名 非 摃丸 米粉 莫屬 每次 吃\n",
      "想 吃點 樣 手機 搜尋 有家 拉麵 店\n",
      "身為 日式拉麵 愛好者 最愛 豚骨拉麵\n",
      "吃 吃 更新 美食 旅遊 情報 來到 新竹市 關新 東路 關新二 街口\n",
      "博多 一幸 舍 轉角 路上 停車 格還\n",
      "碰碰運氣 找個 車位 店內 座位 一人 座\n",
      "幾張 方桌 用餐 不是 用餐 時間\n",
      "店 內人 不多 省去 等待時間 桌上 水壺\n",
      "自助 倒水 飲用 菜單\n",
      "拉麵 一 共有 6 口味\n",
      "價位 230 小菜 像是 餃子 炸雞 叉燒飯 價錢 要加 一成 服務費\n",
      "實說 價位 真的 不太 親切 拉麵 客 製 化\n",
      "包括 選擇 鹹度 麵 軟硬 度 青蔥 拉麵 沒有 糖心蛋\n",
      "愛吃 糖心蛋 要點 一下 囉 桌上 佐料 添加\n",
      "拉麵 味道 不夠 加 拉麵 醬 芝麻 黑胡椒 粉\n",
      "蒜頭 自行 調味 辛子 高菜 跟紅 薑 無限 自助 取用 點好\n",
      "開放式 廚房 師傅 拉麵 豚 骨 香氣 陣陣 傳來\n",
      "餓 我點 博多 濃厚 豚骨拉麵\n",
      "滿滿的 脂泡 配料 一 共有 叉燒 兩片 木耳 青蔥\n",
      "蛋則 加點 習慣 吃 拉麵 先 品嘗 一口 湯\n",
      "試試看 濃厚 豚骨拉麵 湯頭 實說 這碗 豚骨拉麵 的湯 算是 濃稠\n",
      "不到 理想 中 甜度 香氣 叉燒 算是 比較 不 滿意 地方\n",
      "一幸 舍 叉燒 相當 薄 咬起來 不太 過癮 之外\n",
      "口感 不夠 軟 香氣 不足\n",
      "嚼 無味 麵條 則是 極細 麵\n",
      "很 適合 搭配 豚骨拉麵 吸滿 湯汁 送入 口中\n",
      "咬勁 不錯 糖心蛋 一整 顆\n",
      "咬開 爆漿 蛋白 滑嫩 蛋黃 香氣 十足\n",
      "還挺 滿意 同行 友人 點的紅 拉麵\n",
      "明太子 做 調味 湯頭 呈現 紅色\n",
      "喝 微辣 口感\n",
      "鹹度 這紅 拉麵 湯頭 一 喝 還好\n",
      "越 喝 越 回味 濃厚 拉麵 更 有特色\n",
      "比較 記憶 點\n",
      "一碗 三百元 配料 蔥 木耳 叉燒\n",
      "單薄 餐 心得 吃 博多 一幸 舍 拉麵 紅 拉麵 濃厚 表現 較佳 說 濃厚 不至於 不好吃 沒有 想 回訪 衝動 價位 不是 很 親切\n",
      "收取 一成 服務費 算是 一點 小失望 囉 博多 一幸 舍 新竹市 東區 關新 東路 256 號 03 577 3530 11 00 22 00 跟著 尼豪 旅遊 吃 美食\n"
     ]
    }
   ],
   "source": [
    "print ifoodie.values()[ri]['_id']\n",
    "for ele in art:\n",
    "    print ' '.join(ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./Workspace/data/testDD.json', 'w') as f:\n",
    "    json.dump(result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'negativeSubject': [[u'\\u9ebb\\u8fa3\\u71d9', u'\\u5f88\\u4e45'], [u'\\u7d05\\u6cb9\\u6284\\u624b', u'\\u5f88\\u4e45']], u'_id': u'b1', u'positiveSubject': [[u'\\u6c23\\u6ce1\\u98f2\\u6599', u'\\u591a\\u7a2e'], [u'\\u6c99\\u62c9', u'\\u7368\\u4e00\\u7121\\u4e8c'], [u'\\u751f\\u9b5a\\u7247', u'\\u591a\\u7a2e'], [u'\\u80e1\\u9ebb\\u8c46\\u8150', u'\\u81ea\\u88fd'], [u'\\u80e1\\u9ebb\\u91ac', u'\\u597d\\u5403'], [u'\\u6c99\\u62c9', u'\\u5920\\u5473'], [u'\\u96de\\u817f\\u8089', u'\\u5ae9'], [u'\\u9eb5\\u98df', u'\\u9a5a\\u8a1d'], [u'\\u6ef7\\u8089', u'\\u81ea\\u88fd'], [u'\\u8c46\\u8150', u'\\u611b\\u5403'], [u'\\u9d28\\u8840', u'\\u4e0d\\u932f'], [u'\\u6284\\u624b', u'\\u4e0d\\u932f'], [u'\\u96de\\u6392', u'ok'], [u'\\u852c\\u83dc', u'\\u89e3\\u81a9'], [u'\\u86b5\\u4ed4', u'\\u98fd\\u6eff'], [u'\\u863f\\u8514', u'\\u597d\\u5403'], [u'\\u751f\\u9b5a\\u7247', u'\\u6700\\u611b']], u'score': 63.5}\n"
     ]
    }
   ],
   "source": [
    "with open('./Workspace/data/testDD.json', 'r') as f:\n",
    "    dd = json.load(f)\n",
    "print dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61777\n",
      "再訪 吉祥 小館\n",
      "主 以時 未 嚐到 菜色 目標 試吃 菜色\n",
      "細節 詳細 menu 部份 請 初訪 文章 吃 快炒 肯定 飲料\n",
      "正字 不在\n",
      "肯定 不會 酒 鍋煲 獅子頭 150 塊 大洋 快炒 吃 獅子頭\n",
      "湯頭 部份 自然 不能 有太高 期待\n",
      "白菜 部份 是還 保有 些許 青 脆口 感 獅子頭 總共 四粒\n",
      "圓滾滾 樣子 還算 飽滿\n",
      "沒有 美味 湯頭 相輔相成\n",
      "吃 單純 獅子頭 豬絞肉 肉味\n",
      "q 軟 口感 中 摻雜 茡 薺 一點點 爽脆\n",
      "獅子頭 不算 難吃\n",
      "和湯 白菜\n",
      "感覺 各走各的路\n",
      "沒有 太 相得益彰 感覺 蔭鼓 鮮蚵 180 塊 大洋 光看 鮮蚵 這份 量\n",
      "些許 期待 鮮蚵 鮮度 還滿 不錯\n",
      "熟度 頗為 恰當\n",
      "九分熟 調味 不會 有過 厚重\n",
      "不愛 吃白飯 捧 油\n",
      "湯汁 拿來 拌飯\n",
      "一舉兩得 空心菜 炒 90 塊 大洋 實在 很 想點 山菜 類的 吃\n",
      "可惜 貓 p 太 挑食 無法 接受\n",
      "\n",
      "空心菜 份量 非常 夠\n",
      "疊得 高高的 很 爽度\n",
      "至少 份量 熟度 還滿 恰當\n",
      "調味 清淡 糖醋魚片 140 塊 大洋 糖醋魚片 味道 不差\n",
      "調味 是貓 p 最愛 重 芡 重 糖醋\n",
      "台灣鯛 無土 味 鮮甜 味 自是 不錯\n",
      "打得 很重 芡 水 魚片 外頭 粉 過於 厚重\n",
      "吃 膩\n",
      "算是 小小 可惜 之處 鐵板牛柳 200 塊 大洋 貓 p 最愛 重 口味 鐵板\n",
      "這道 完全符合 需求 xd 黑胡椒 調味 沒\n",
      "黑胡椒 辛香 微微 辣 相當 吊人 胃口 丫二訪 吉祥\n",
      "是因為 點的 菜色 關係\n",
      "整體 評價 初訪 來得 好些 至少 沒有 吃到 太 失敗 菜色\n",
      "上次 完食\n",
      "同行 的貓 p 一改 前言\n",
      "直說 實在 好吃 太多 重 口味 喜好 上門 沒辦法 說個準\n",
      "兩次 造訪 沒有 非常 詬病\n",
      "菜色 部份 價位\n",
      "不算 差\n",
      "這間 雨聲 街 這條 算 偏僻 小道 生意 火熱\n",
      "不是 沒有 道理 3 y\n",
      "o0 店家 資訊 吉祥 小館 02 28383250 台北市 士林區 雨聲 街 161 號 pm1700\n",
      "pm2200 a\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print ri\n",
    "for ele in ifoodie.values()[ri]['article']:\n",
    "    print ' '.join(ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deleteBadWords(StrIn):\n",
    "    Str_BadWords = u'延伸閱讀|連絡方式|電話預約|電話|營業時間|週一|週二|週三|週四|週五|週六|週日|周一|周二|周三|周四|周五|周六|\\\n",
    "                    |周日|假日|公休|平日|地址|粉絲團|星期|禮拜|時間限制|您或許對這些文章有興趣|造訪日期|全年無休|最後點餐|營業|AM|PM|上一篇|下一篇|\\\n",
    "                    |分享此文|您可能喜歡的文章|懶人包|臉書|Facebook|facebook|FB|fb|全世界便宜住宿看這兒|下載愛食記App隨時觀看|按個讚啦|喜歡我的分享嗎|\\\n",
    "                    |瘋台灣民宿網|官方網站|瀏覽人次|最新消息|餐廳名稱|消費時間|無圖文版|網誌|Postedonby|新鮮關注回聲|Christabelle的藝想世界部落格由製作|\\\n",
    "                    |也許對這些文章也有興趣|發表迴響|電子郵件|必要欄位標記|電子郵件|個人網站|輸入圖片顯示文字好證明你不是機器人|站內搜尋分類|最新動態|\\\n",
    "                    |並不會被公開|你的位址 |迴響名稱|用餐日期|留言|載入中|文章文章|粉絲頁|發表|每人平均價位|按個讚|推薦你閱讀|Instagram|instagram|\\\n",
    "                    |美食地圖|版權所有|網友回應|歡迎加入|標籤|著作權聲明|非經授權|不得轉載'\n",
    "    strClean = re.sub(Str_BadWords,'',StrIn)\n",
    "    return strClean\n",
    "\n",
    "def EnglishFullToHalf(StrIn):\n",
    "    def transform(ele):\n",
    "        alphabetInt = int(repr(ele.group('number'))[4:8],16)\n",
    "        transAlphabeInt = alphabetInt - 65248\n",
    "        return binascii.a2b_hex(hex(transAlphabeInt)[2:4])\n",
    "    pattern = re.sub(u'(?P<number>[\\uff21-\\uff3a\\uff41-\\uff5a])', transform, StrIn)\n",
    "    return pattern\n",
    "\n",
    "def setBreakPoint(StrIn):\n",
    "    pattern = u'[,，.。~～!！?？；]+'\n",
    "    result = re.sub(pattern, ' ', StrIn)\n",
    "    return result\n",
    "\n",
    "def retain_English_Chinese_Arabic_numerals(StrIn):\n",
    "    Str_English_Chinese = u'([^ 0-9a-zA-Zａ-ｚＡ-Ｚ\\u4E00-\\u9FCC]+)'\n",
    "    #Str_English_Chinese = u'([^a-z^A-Z^ａ-ｚ^Ａ-Ｚ^^0-9^０-９^\\u3105-\\u3129^\\u4E00-\\u9FCC]+)'\n",
    "    #\\u3105-\\u3129為所有注音符號 \n",
    "    #\\u4E00-\\u9FCC為所有中文\n",
    "    strClean = re.sub(Str_English_Chinese,'',StrIn)\n",
    "    return strClean\n",
    "\n",
    "def removeSentimentInAds(StrIn):\n",
    "    pattern = u'.*(喜歡|推薦|喜愛).{0,6}(文章|本文|介紹)'\n",
    "    def sub(match):\n",
    "        string = match.group(0)\n",
    "        type1 = match.group(1) if match.group(1) else ''\n",
    "        r = string.replace(type1,'')\n",
    "        return r\n",
    "    result = re.sub(pattern, sub, StrIn)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "def removeTag(soup,tag):\n",
    "    [x.extract() for x in soup.select(tag)]\n",
    "\n",
    "res = requests.get('https://banbi.tw/2014-01-21-381/')\n",
    "res.encoding = 'utf-8'\n",
    "soup = bs(res.text,'html.parser')\n",
    "removeTag(soup,'script')\n",
    "removeTag(soup,'a')\n",
    "removeTag(soup,'.rank')\n",
    "removeTag(soup,'iframe')\n",
    "xuite = soup.select('.blogbody')\n",
    "pixnet = soup.select('.article-content-inner')\n",
    "ifoodie = soup.select('#blog_content')\n",
    "miha = soup.select('#content article p')\n",
    "banbi = soup.select('article')\n",
    "art = banbi\n",
    "line = [a.text for a in art if a.text!=\"\"]\n",
    "st = \"\".join(\"\".join(line).split()).replace(u'延伸閱讀','').replace('^','')\n",
    "st = deleteBadWords(st)\n",
    "st = EnglishFullToHalf(st)\n",
    "st = setBreakPoint(st)\n",
    "st = retain_English_Chinese_Arabic_numerals(st)\n",
    "st = st.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "情緒總分：75\n",
      "positive 乳腐 美食\n",
      "positive 白饅頭 柔軟\n",
      "positive 青江菜 多汁\n",
      "positive 北京烤鴨 很高\n",
      "positive 烤鴨 愛吃\n",
      "positive 蝦子 愛吃\n",
      "positive 醬汁 適中\n",
      "positive 韭菜 愛吃\n",
      "positive 鍋餅 酥脆\n",
      "positive 焢肉 好吃\n",
      "positive 白饅頭 柔軟\n",
      "positive 青江菜 多汁\n",
      "positive 鴨肉 脆口\n",
      "positive 湯頭 鮮美\n",
      "positive 白菜 軟嫩\n",
      "positive 甜品 開心\n",
      "positive 花生仁 清甜\n",
      "positive 紅棗 香\n",
      "positive 水果 鮮甜\n",
      "negative 韭菜 喜歡\n",
      "negative 小黃瓜 可惜\n",
      "negative 杏仁 不喜\n",
      "negative 紅棗 煮軟\n"
     ]
    }
   ],
   "source": [
    "art = st\n",
    "s_analysis = SentimentAnalysis(negdict, posdict, nodict, plusdict, question, 'b1', 'a1',food)\n",
    "for sent in art:\n",
    "    s_analysis.sentimentScore(list(jieba.cut(sent)))\n",
    "print '情緒總分：%s' % str(s_analysis.score)\n",
    "for ele in s_analysis.positiveSubject:\n",
    "    print 'positive', ele[0], ele[1]\n",
    "for ele in s_analysis.negativeSubject:\n",
    "    print 'negative', ele[0], ele[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "情緒總分：0\n"
     ]
    }
   ],
   "source": [
    "sentence = u'不是非常不難吃'\n",
    "s_analysis = SentimentAnalysis(negdict, posdict, nodict, plusdict, question, 'b1', 'a1',food)\n",
    "s_analysis.sentimentScore(list(jieba.cut(sentence)))\n",
    "print '情緒總分：%s' % str(s_analysis.score)\n",
    "for ele in s_analysis.positiveSubject:\n",
    "    print 'positive', ele[0], ele[1]\n",
    "for ele in s_analysis.negativeSubject:\n",
    "    print 'negative', ele[0], ele[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subject = {}\n",
    "for ele in text: \n",
    "    article = text[ele]['article']\n",
    "    SA = SentimentAnalysis(negdict, posdict, nodict, plusdict, question, ele, text[ele]['author_id'])\n",
    "    SA.sentimentScore(article)\n",
    "    obj2dict = SA.__dict__\n",
    "    [obj2dict.pop(key,None) for key in ['negdict','posdict','nodict','plusdict', 'question']]\n",
    "    subject[ele] = obj2dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 丟檔案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open('./Workspace/data/subject.json', 'w') as f:\n",
    "    json.dump(subject,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
